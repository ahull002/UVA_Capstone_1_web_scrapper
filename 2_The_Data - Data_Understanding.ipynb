{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS5010, Summer 2020 Capstone 1 Web Scraper\n",
    "Data Understanding </H3>\n",
    "    \n",
    "Data Features:\n",
    "\n",
    "___Initial Data Collection___: For the Data Collection we found two websites to scrape. One website was data regarding humidity levels across all states in The United States of America. The other website was COVID-19 Cases by State which included Total, New Cases, and Deaths. The procedure included webscraping these websites, cleaning the data, and merging them into one csv file. This section helped lay the foundation for the data description, analysis and testing/evaluation aspects of this project. </li>\n",
    "\n",
    "___Data Description___: The Data Description describes the data acquired highlighting the format and source of data. Additionally, the number of cases/variables, with their descriptions will be explained together with necessary information. This will help evaluate whether the data is suitable and a sufficient case for the analysis of interest. \n",
    "\n",
    "___Exploratory Data Analysis (EDA)___: EDA will examine the data more closely. It will highlight the first findings and initial hypothesis of the study of interest. Aggregates, Statistical Analysis, Relationships between variables, and Visualizations (graphs and plots) will be included for further analysis and data exploration. \n",
    "\n",
    "\n",
    "___Data Testing___: The Data Testing portion will use the data analysis to come up with queries to reveal intersting and useful information about our data and topic of interest. \n",
    "\n",
    "___Data Quality___: The Data Quality will list our conclusions. Here we will summarize our findings, explain how these results could be used by others such as government and health officials. Evaluations and improvements to this study project will be described for future use. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initial Data Collection Report__\n",
    "\n",
    "\n",
    "\n",
    "    The first dataset used was put together by the WorldOMeters information group. The dataset is updated daily to reflect the update count of each of the variables of interest. These include the Total Cases, Deaths, Tests, New Deaths, Cases and Active Deaths of the COVID 19 Pandemic. The data can be found at https://www.worldometers.info/coronavirus/country/us/. \n",
    "    \n",
    "    The second dataset used was put together by the USA World Media Group. The dataset rank locations with Average Humidity Data by State. The dataset show cases the State, its population and Average Humidity level in percentage. The data can be found at www.usa.com/rank/us--average-humidity--state-rank.htm. \n",
    "    \n",
    "    The following Data Collection Report is a simple listing of the data sources acquired along with their locations, the procedures used to procure them, and any difficulties encountered. This section will aid both with future replication of this project and with the execution of similar future projects.\n",
    "\n",
    "__Data Collection:__\n",
    "\n",
    "1.\tData Source 1: COVID 19 Cases by State in the United States  \n",
    "2.\tLocation: https://www.worldometers.info/coronavirus/country/us/\n",
    "3.\tCOVID 19 Cases by State: Total Cases, Deaths, New Cases, Deaths and Active Cases from all States in The USA exctracted for analysis. Dataset updates daily.\n",
    "4.\tMethod: This dataset shows the Total COVID 19 Cases by State on a daily basis. New cases are updated daily, together with the total deaths, new deaths, and active cases. It contains data from all 50 States showing 4,638,326 total cases with new cases, total deaths, new deaths and active cases being the nested data. \n",
    "a.\tCases are reported to Health Officals in every state and county. Data is collected and available for the public to view. Among these cases, deaths are reported too. No demographic or personal information is included. Each case is represented as is with no other information is provided.\n",
    "b.\tThe data are contained in the files covid19_states.csv. More details about the contents and use of the file follows.\n",
    "5.\tObstacles: This is a dataset that is updated daily. As such, due to the daily change it may not be an appropriate dataset to share as data may have been updated from the time the webpage was scraped. However, from daily monitoring of COVID cases this project data analysis would not be affected.  \n",
    "\n",
    "1.\tData Source 2: United States Average Humidity State Rank  \n",
    "2.\tLocation: www.usa.com/rank/us--average-humidity--state-rank.htm. \n",
    "3.\tUnited States, Average Humidity Percentage by State: States and Ranked based on their average humidity percetage level in descending order. \n",
    "4.\tMethod: This dataset shows the average humidity level across all states. Population of each state is included as well.  \n",
    "a.\tThe data are contained in the covid19_states_humidity.csv. More details about the contents and use of the file follows.\n",
    "5.\tObstacles: This is a dataset that appears to be updated once a year gathering humidity levels from states across different time periods within a year and finding the average. As such, gathering average levels of humidity could mean the data is measured over time in the same sample group. Hence, we are unsure if the data is from one county or several. \n",
    "    \n",
    "__covid19 states__and__covid19 states humidity__\n",
    "csv file containing covid19 cases across states and humidity levels are included in the dataset. Humidity levels are consistent with those from the website. Covid cases were obtained and are consistent with data from first week of July. \n",
    "\n",
    "__USA States Humidity Levels and COVID19 Cases Merged Data File Structure (covid19_states_humidityandcases.csv)__\n",
    "All humidity percentage levels by State, and Covid19 cases, deaths are merged and contained in the file covid19_states_humidityandcases.csv. Each line of this file after the header row represents each state, its humidity level, the total number of covid cases, total deaths, new/active cases and new deaths. The following format was applied: \n",
    "\n",
    "USAState, TotalCases, NewCases, TotalDeaths, NewDeaths, ActiveCases, AverageHumidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# settings\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# data viz imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building scrapper: writing elegant parsing/scrapping function to parse data from internet\n",
    "def get_soup(url):\n",
    "    \"\"\"Constructs and returns a soup using the HTML content of `url` passed\"\"\"\n",
    "    # initialize a session\n",
    "    session = requests.Session()\n",
    "    # make the request\n",
    "    html = session.get(url)\n",
    "    # return the soup\n",
    "    return bs(html.content, \"html.parser\")\n",
    " \n",
    "def get_tables(soup):\n",
    "    \"\"\"Extracts and returns all tables in a soup object\"\"\"\n",
    "    return soup.find_all(\"table\",{\"id\":\"usa_table_countries_today\"})\n",
    "\n",
    "def get_table_headers(table):\n",
    "    \"\"\"Given a table soup, returns all the headers\"\"\"\n",
    "    headers = []\n",
    "    for th in table.find(\"tr\").find_all(\"th\"):\n",
    "        headers.append(th.text.strip())\n",
    "    return headers\n",
    " \n",
    "def get_table_rows(table):\n",
    "    \"\"\"Given a table, returns all its rows\"\"\"\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        cells = []\n",
    "        # grab all td tags in this table row\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) == 0:\n",
    "            # if no td tags, search for th tags\n",
    " \n",
    "            ths = tr.find_all(\"th\")\n",
    "            for th in ths:\n",
    "                cells.append(th.text.strip())\n",
    "        else:\n",
    "            # use regular td tags\n",
    "            for td in tds:\n",
    "                cells.append(td.text.strip())\n",
    "        rows.append(cells)\n",
    "    return rows\n",
    "\n",
    "def main(url):\n",
    "    # get the soup\n",
    "    soup = get_soup(url)\n",
    "    # extract all the tables from the web page\n",
    "    tables = get_tables(soup)\n",
    "    # iterate over all tables\n",
    "    for i, table in enumerate(tables, start=1):\n",
    "        # get the table headers\n",
    "        headers = get_table_headers(table)\n",
    "        # get all the rows of the table\n",
    "        rows = get_table_rows(table)\n",
    "        # save table as csv file\n",
    "        table_name = f\"table-{i}\"\n",
    "        save_as_csv(table_name, headers, rows)    \n",
    "\n",
    "def save_as_csv(table_name, headers, rows):\n",
    "    pd.DataFrame(rows, columns=headers).to_csv(\"data\\covid19_states.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data source: df1_covidcases\n",
    "\n",
    "# step1. instantiating scrapper function        \n",
    "main(\"https://www.worldometers.info/coronavirus/country/us/\")\n",
    "# step2. setting up column names: col_list\n",
    "col_list = [\"USAState\",\"TotalCases\",\"NewCases\",\"TotalDeaths\",\"NewDeaths\",\"ActiveCases\"]\n",
    "# step3. reading data in using read_csv, and casting col_list to headers: df1_covidcases\n",
    "df1_covidcases = pd.read_csv(\"data/covid19_states.csv\", usecols=col_list)\n",
    "\n",
    "\n",
    "# get data source: df2_humidity\n",
    "\n",
    "# step1. assign webpage address of interest that we will scrape\n",
    "url = 'http://www.usa.com/rank/us--average-humidity--state-rank.htm#:~:text=Rank%20Average%20Humidity%20%E2%96%BC%20State%20%2F%20Population%201.,4.%2080.76%25%20Maine%20%2F%201%2C328%2C535%2047%20more%20rows'\n",
    "# step2. use pandas read_html() tool to read and parse our site. The [0] indicates that we want to grab the first table on the webpage\n",
    "df2_humidity = pd.read_html(url)[0]\n",
    "# step3. set first row to headers\n",
    "df2_humidity = df2_humidity.rename(columns=df2_humidity.iloc[0])\n",
    "# step 4. drop duplicated header row inplace\n",
    "df2_humidity.drop(df2_humidity.index[0], inplace=True)\n",
    "# step 5. split data by the delimeter \"/\" into: 'State' and 'Population'\n",
    "df2_humidity[['State','Population']] = df2_humidity['State / Population'].str.split(\"/\",expand=True)\n",
    "# step 6. drop 'State / Population' column\n",
    "df2_humidity.drop(columns=['State / Population'], inplace=True)\n",
    "# step 7. rename columns using dictionary\n",
    "df2_humidity.rename(columns={'Average Humidity ▼' : 'Average Humidity', 'State' : 'USAState'},inplace=True)\n",
    "# step 8. write file to .csv\n",
    "df2_humidity.to_csv(\"data\\covid19_states_humidity.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        USAState TotalCases NewCases TotalDeaths  NewDeaths ActiveCases\n",
      "0      USA Total  3,359,838   +4,192     137,436       33.0   1,731,677\n",
      "1       New York    426,807      NaN      32,393        NaN     227,391\n",
      "2     California    319,985      NaN       7,030        4.0     227,398\n",
      "3          Texas    259,465      NaN       3,228        NaN     128,357\n",
      "4        Florida    254,511      NaN       4,197        NaN     218,244\n",
      "5     New Jersey    180,672      NaN      15,603        NaN      88,899\n",
      "6       Illinois    154,094      NaN       7,369        NaN      31,278\n",
      "7        Arizona    119,930      NaN       2,151        NaN     103,385\n",
      "8        Georgia    114,401      NaN       2,996        NaN      93,715\n",
      "9  Massachusetts    111,398      NaN       8,310        NaN       8,741\n",
      "   Rank Average Humidity        USAState   Population\n",
      "1    1.           82.01%           Iowa     3,078,116\n",
      "2    2.           81.86%  New Hampshire     1,321,069\n",
      "3    3.           81.46%         Alaska       728,300\n",
      "4    4.           80.76%          Maine     1,328,535\n",
      "5    5.           80.74%   North Dakota       704,925\n",
      "6    6.           80.61%      Minnesota     5,383,661\n",
      "7    7.           80.54%   South Dakota       834,708\n",
      "8    8.           80.40%        Montana     1,006,370\n",
      "9    9.           80.36%     California    38,066,920\n",
      "10  10.           79.71%       Colorado     5,197,580\n"
     ]
    }
   ],
   "source": [
    "# check data frames from scrapper: df1_covidcases & df2_humidity\n",
    "print(df1_covidcases.head())\n",
    "print(df2_humidity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   USAState     64 non-null     object \n",
      " 1   TotalCases   64 non-null     object \n",
      " 2   NewCases     15 non-null     object \n",
      " 3   TotalDeaths  62 non-null     object \n",
      " 4   NewDeaths    9 non-null      float64\n",
      " 5   ActiveCases  64 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 3.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check the info for df1_covidcases\n",
    "# We see that there are some null values that we will need to work out. Aslo we may need to moralize values within each record for leading and lagging spaces.\n",
    "print(df1_covidcases.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51 entries, 1 to 51\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Rank              51 non-null     object\n",
      " 1   Average Humidity  51 non-null     object\n",
      " 2   USAState          51 non-null     object\n",
      " 3   Population        51 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check the info for df1_covidcases\n",
    "# We see that the values listed here are a lot more pure. To merge the dataframes we just need to esure primary and foreign keys are consistent on USAState\n",
    "print(df2_humidity.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAState</th>\n",
       "      <th>TotalCases</th>\n",
       "      <th>NewCases</th>\n",
       "      <th>TotalDeaths</th>\n",
       "      <th>NewDeaths</th>\n",
       "      <th>ActiveCases</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Average Humidity</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.</td>\n",
       "      <td>82.01%</td>\n",
       "      <td>3,078,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.</td>\n",
       "      <td>81.86%</td>\n",
       "      <td>1,321,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.</td>\n",
       "      <td>81.46%</td>\n",
       "      <td>728,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.</td>\n",
       "      <td>80.76%</td>\n",
       "      <td>1,328,535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.</td>\n",
       "      <td>80.74%</td>\n",
       "      <td>704,925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         USAState TotalCases NewCases TotalDeaths  NewDeaths ActiveCases Rank Average Humidity  Population\n",
       "0           Iowa         NaN      NaN         NaN        NaN         NaN   1.           82.01%   3,078,116\n",
       "1  New Hampshire         NaN      NaN         NaN        NaN         NaN   2.           81.86%   1,321,069\n",
       "2         Alaska         NaN      NaN         NaN        NaN         NaN   3.           81.46%     728,300\n",
       "3          Maine         NaN      NaN         NaN        NaN         NaN   4.           80.76%   1,328,535\n",
       "4   North Dakota         NaN      NaN         NaN        NaN         NaN   5.           80.74%     704,925"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge wrangled dataframes\n",
    "# we see that there is an issue with the primary and foreign keys i.e. lagging space or even spelling\n",
    "test_merge = pd.merge(df1_covidcases,df2_humidity, how='right', on='USAState')\n",
    "test_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                         Alabama\n",
       "36                        Alabama \n",
       "49                          Alaska\n",
       "3                          Alaska \n",
       "7                          Arizona\n",
       "14                        Arizona \n",
       "30                        Arkansas\n",
       "31                       Arkansas \n",
       "2                       California\n",
       "9                      California \n",
       "24                        Colorado\n",
       "10                       Colorado \n",
       "21                     Connecticut\n",
       "16                    Connecticut \n",
       "38                        Delaware\n",
       "50                       Delaware \n",
       "62           Diamond Princess Ship\n",
       "40            District Of Columbia\n",
       "24           District of Columbia \n",
       "58                 Federal Prisons\n",
       "4                          Florida\n",
       "28                        Florida \n",
       "8                          Georgia\n",
       "39                        Georgia \n",
       "60             Grand Princess Ship\n",
       "52                            Guam\n",
       "51                          Hawaii\n",
       "47                         Hawaii \n",
       "41                           Idaho\n",
       "12                          Idaho \n",
       "6                         Illinois\n",
       "30                       Illinois \n",
       "20                         Indiana\n",
       "38                        Indiana \n",
       "27                            Iowa\n",
       "1                            Iowa \n",
       "35                          Kansas\n",
       "15                         Kansas \n",
       "34                        Kentucky\n",
       "37                       Kentucky \n",
       "12                       Louisiana\n",
       "41                      Louisiana \n",
       "46                           Maine\n",
       "4                           Maine \n",
       "14                        Maryland\n",
       "49                       Maryland \n",
       "9                    Massachusetts\n",
       "44                  Massachusetts \n",
       "13                        Michigan\n",
       "46                       Michigan \n",
       "22                       Minnesota\n",
       "6                       Minnesota \n",
       "26                     Mississippi\n",
       "40                    Mississippi \n",
       "29                        Missouri\n",
       "22                       Missouri \n",
       "48                         Montana\n",
       "8                         Montana \n",
       "59                   Navajo Nation\n",
       "32                        Nebraska\n",
       "18                       Nebraska \n",
       "31                          Nevada\n",
       "20                         Nevada \n",
       "43                   New Hampshire\n",
       "2                   New Hampshire \n",
       "5                       New Jersey\n",
       "51                     New Jersey \n",
       "37                      New Mexico\n",
       "35                     New Mexico \n",
       "1                         New York\n",
       "42                       New York \n",
       "11                  North Carolina\n",
       "27                 North Carolina \n",
       "44                    North Dakota\n",
       "5                    North Dakota \n",
       "53        Northern Mariana Islands\n",
       "16                            Ohio\n",
       "23                           Ohio \n",
       "33                        Oklahoma\n",
       "34                       Oklahoma \n",
       "39                          Oregon\n",
       "11                         Oregon \n",
       "10                    Pennsylvania\n",
       "21                   Pennsylvania \n",
       "54                     Puerto Rico\n",
       "36                    Rhode Island\n",
       "25                   Rhode Island \n",
       "18                  South Carolina\n",
       "48                 South Carolina \n",
       "42                    South Dakota\n",
       "7                    South Dakota \n",
       "17                       Tennessee\n",
       "43                      Tennessee \n",
       "3                            Texas\n",
       "29                          Texas \n",
       "63                          Total:\n",
       "57                     US Military\n",
       "0                        USA Total\n",
       "55    United States Virgin Islands\n",
       "28                            Utah\n",
       "45                           Utah \n",
       "50                         Vermont\n",
       "32                        Vermont \n",
       "56                 Veteran Affairs\n",
       "15                        Virginia\n",
       "33                       Virginia \n",
       "23                      Washington\n",
       "17                     Washington \n",
       "45                   West Virginia\n",
       "19                  West Virginia \n",
       "25                       Wisconsin\n",
       "26                      Wisconsin \n",
       "61               Wuhan Repatriated\n",
       "47                         Wyoming\n",
       "13                        Wyoming \n",
       "Name: USAState, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we look at value fields for primary keys to see why they are off. We will need to address this in the data preparation.\n",
    "frames = [df1_covidcases['USAState'], df2_humidity['USAState']]\n",
    "result = pd.concat(frames).sort_values()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to .csv\n",
    "# write out covid19_states.csv\n",
    "df1_covidcases.to_csv(\"data\\covid19_states_cases.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# write out covid19_states_humidity.csv\n",
    "df2_humidity.to_csv(\"data\\covid19_states_humidity.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
